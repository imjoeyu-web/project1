import streamlit as st
import base64
import os
import requests
import re
import json
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS

# ============================================================
# í˜ì´ì§€ ë° ê¸°ë³¸ ì„¤ì •
# ============================================================
st.set_page_config(
    page_title="ìƒˆì‹¹ ìŠ¤ë§ˆíŠ¸ AI ì·¨ì—… ì»¨ì„¤í„´íŠ¸",
    page_icon="ğŸ¤–",
    layout="wide",
)

# Document í´ë” ìë™ ìƒì„±
if not os.path.exists("Document"):
    os.makedirs("Document")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "vector_store" not in st.session_state:
    st.session_state.vector_store = None
if "search_history" not in st.session_state:
    st.session_state.search_history = []

# ============================================================
# ì»¤ìŠ¤í…€ CSS (All-White & Clean Blue í…Œë§ˆ)
# ============================================================
st.markdown(
    """
<style>
    .stApp { background-color: #ffffff; }
    
    [data-testid="stSidebar"] {
        background-color: #ffffff;
        border-right: 1px solid #f0f2f6;
    }

    .user-box {
        background-color: #0066cc; 
        color: white; 
        padding: 15px;
        border-radius: 20px 20px 5px 20px; 
        margin: 10px 0 10px 20%;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
        font-size: 15px;
    }
    .ai-box {
        background-color: #f8f9fa; 
        color: #1a1a1a; 
        padding: 15px;
        border-radius: 20px 20px 20px 5px; 
        margin: 10px 20% 10px 0;
        border: 1px solid #e9ecef;
        box-shadow: 0 2px 4px rgba(0,0,0,0.02);
        font-size: 15px;
    }

    .stButton>button {
        width: 100%;
        border-radius: 8px;
        border: 1px solid #0066cc;
        background-color: white;
        color: #0066cc;
        font-weight: 600;
        transition: all 0.3s;
    }
    .stButton>button:hover {
        background-color: #0066cc;
        color: white;
    }
    
    .stTextInput>div>div>input, .stTextArea>div>div>textarea {
        border-color: #e9ecef !important;
    }
    
    .search-result {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        border-left: 4px solid #0066cc;
    }
    .source-link {
        color: #0066cc;
        font-size: 0.9em;
    }
    
    .mode-badge {
        display: inline-block;
        padding: 3px 10px;
        border-radius: 12px;
        font-size: 12px;
        font-weight: 600;
        margin-bottom: 10px;
    }
    .mode-rag {
        background-color: #e8f5e9;
        color: #2e7d32;
    }
    .mode-web {
        background-color: #e3f2fd;
        color: #1565c0;
    }
    .mode-llm {
        background-color: #fff3e0;
        color: #e65100;
    }
</style>
""",
    unsafe_allow_html=True,
)


def get_base64_image(image_path):
    try:
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode()
    except:
        return None


# ============================================================
# RAG: ì¸ë±ì‹± í•¨ìˆ˜
# ============================================================
def perform_indexing():
    with st.spinner("Document í´ë” ë‚´ ë¬¸ì„œë¥¼ ì¸ë±ì‹± ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            loader = PyPDFDirectoryLoader("Document/")
            documents = loader.load()
            if not documents:
                st.warning("Document í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=800, chunk_overlap=100
            )
            splits = text_splitter.split_documents(documents)
            embeddings = OpenAIEmbeddings(api_key=st.secrets["OPENAI_API_KEY"])
            vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
            st.session_state.vector_store = vectorstore
            st.success(f"ì¸ë±ì‹± ì™„ë£Œ! ì´ {len(splits)}ê°œì˜ ì§€ì‹ ì¡°ê°ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ì¸ë±ì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# ============================================================
# ì›¹ ê²€ìƒ‰ í•¨ìˆ˜
# ============================================================
def search_naver_blog(query: str, num_results: int = 10) -> list:
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ API"""
    url = "https://openapi.naver.com/v1/search/blog.json"
    headers = {
        "X-Naver-Client-Id": st.secrets["NAVER_CLIENT_ID"],
        "X-Naver-Client-Secret": st.secrets["NAVER_CLIENT_SECRET"],
    }
    params = {
        "query": query,
        "display": num_results,
        "sort": "sim",
    }

    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        results = response.json()

        search_results = []
        for item in results.get("items", []):
            title = re.sub(r"<[^>]+>", "", item.get("title", ""))
            description = re.sub(r"<[^>]+>", "", item.get("description", ""))
            search_results.append(
                {
                    "title": title,
                    "link": item.get("link", ""),
                    "snippet": description,
                    "source": "ë„¤ì´ë²„ ë¸”ë¡œê·¸",
                    "date": item.get("postdate", ""),
                }
            )
        return search_results
    except Exception as e:
        return []


def search_naver_cafe(query: str, num_results: int = 10) -> list:
    """ë„¤ì´ë²„ ì¹´í˜ ê²€ìƒ‰ API"""
    url = "https://openapi.naver.com/v1/search/cafearticle.json"
    headers = {
        "X-Naver-Client-Id": st.secrets["NAVER_CLIENT_ID"],
        "X-Naver-Client-Secret": st.secrets["NAVER_CLIENT_SECRET"],
    }
    params = {"query": query, "display": num_results, "sort": "sim"}

    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        results = response.json()

        search_results = []
        for item in results.get("items", []):
            title = re.sub(r"<[^>]+>", "", item.get("title", ""))
            description = re.sub(r"<[^>]+>", "", item.get("description", ""))
            search_results.append(
                {
                    "title": title,
                    "link": item.get("link", ""),
                    "snippet": description,
                    "source": "ë„¤ì´ë²„ ì¹´í˜",
                    "cafe_name": item.get("cafename", ""),
                }
            )
        return search_results
    except Exception as e:
        return []


def search_web(query: str, sources: list, num_results: int = 5) -> list:
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ + ì¹´í˜ í†µí•© ê²€ìƒ‰"""
    all_results = []
    if "ë„¤ì´ë²„ ë¸”ë¡œê·¸" in sources:
        all_results.extend(search_naver_blog(query, num_results))
    if "ë„¤ì´ë²„ ì¹´í˜" in sources:
        all_results.extend(search_naver_cafe(query, num_results))
    return all_results


# ============================================================
# ì§ˆë¬¸ ë¶„ë¥˜ í•¨ìˆ˜
# ============================================================
def classify_query(query: str, has_vector_store: bool) -> str:
    """
    ì§ˆë¬¸ì„ ë¶„ë¥˜í•˜ì—¬ RAG / LLM / ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ê¸°
    1. SeSAC, ìƒˆì‹¹, êµìœ¡ ê´€ë ¨ â†’ RAG
    2. ê·¸ ì™¸ â†’ LLMì´ íŒë‹¨ (AUTO)
    """
    # SeSAC/êµìœ¡ ê´€ë ¨ í‚¤ì›Œë“œ (RAG ì‚¬ìš©)
    rag_keywords = ["ìƒˆì‹¹", "SeSAC", "ì„±ë™", "ìº í¼ìŠ¤", "êµìœ¡ê³¼ì •", "ìˆ˜ê°•í›„ê¸°", "êµìœ¡ì„±ê³¼", "ì¥í•œí‰", "ë‹µì‹­ë¦¬"]
    
    query_lower = query.lower()
    
    # RAG í‚¤ì›Œë“œ ì²´í¬
    for keyword in rag_keywords:
        if keyword in query_lower:
            return "RAG"
    
    # ê·¸ ì™¸ ì§ˆë¬¸ì€ LLMì´ ìë™ íŒë‹¨í•˜ë„ë¡ AUTO ë°˜í™˜
    return "AUTO"


def determine_search_need(query: str, api_key: str) -> dict:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì´ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨
    Returns: {"need_search": bool, "reason": str, "search_query": str}
    """
    llm = ChatOpenAI(
        model="gpt-5-mini",
        api_key=api_key,
        temperature=1,
    )
    
    classification_prompt = f"""ë‹¹ì‹ ì€ ì§ˆë¬¸ ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.

[ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸ ìœ í˜•]
- ì±„ìš© ê³µê³ , ì‹ ì…/ê²½ë ¥ ëª¨ì§‘ ì†Œì‹, ì±„ìš© ì‚¬ì´íŠ¸(ì›í‹°ë“œ, ì‚¬ëŒì¸ ë“±) ì •ë³´
- íŠ¹ì • ê¸°ì—…ì˜ ì§ë¬´ë³„ ìê²© ìš”ê±´ ë° ìš°ëŒ€ ì‚¬í•­
- ë©´ì ‘ í›„ê¸°, ê¸°ì—… ë¬¸í™”, ì—°ë´‰ ì •ë³´ ë“± ì‹¤ì‹œê°„ ë¦¬ë·°

[ì›¹ ê²€ìƒ‰ì´ í•„ìš” ì—†ëŠ” ì§ˆë¬¸ ìœ í˜•]
- ì¼ë°˜ ì§€ì‹, ê°œë… ì„¤ëª…
- ì½”ë”©, í”„ë¡œê·¸ë˜ë° ë„ì›€
- ìˆ˜í•™, ê³¼í•™ ë“± ë³´í¸ì  ì§€ì‹
- ë²ˆì—­, ë¬¸ë²• êµì •
- ì°½ì‘, ê¸€ì“°ê¸°
- ì¼ë°˜ì ì¸ ì¡°ì–¸

ì§ˆë¬¸: "{query}"

ìœ„ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:
{{"need_search": true, "reason": "ì´ìœ ", "search_query": "ê²€ìƒ‰ì–´"}}
ë˜ëŠ”
{{"need_search": false, "reason": "ì´ìœ ", "search_query": ""}}"""
    
    try:
        response = llm.invoke([HumanMessage(content=classification_prompt)])
        result_text = response.content.strip()
        
        # ```json ë“±ì˜ ë§ˆí¬ë‹¤ìš´ ì œê±°
        if "```" in result_text:
            result_text = re.sub(r'```json\s*', '', result_text)
            result_text = re.sub(r'```\s*', '', result_text)
            result_text = result_text.strip()
        
        # JSON íŒŒì‹± ì‹œë„
        result = json.loads(result_text)
        
        # í•„ìˆ˜ í‚¤ ê²€ì¦
        if "need_search" not in result:
            result["need_search"] = False
        if "reason" not in result:
            result["reason"] = "ìë™ íŒë‹¨"
        if "search_query" not in result:
            result["search_query"] = ""
            
        return result
    except json.JSONDecodeError:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ íŒë‹¨ ì‹œë„
        result_lower = response.content.lower() if response else ""
        if "true" in result_lower or "í•„ìš”" in result_lower:
            return {"need_search": True, "reason": "ì›¹ ê²€ìƒ‰ í•„ìš”ë¡œ íŒë‹¨", "search_query": query}
        return {"need_search": False, "reason": "AI ì§ì ‘ ë‹µë³€ ê°€ëŠ¥", "search_query": ""}
    except Exception as e:
        # ê¸°íƒ€ ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return {"need_search": False, "reason": f"íŒë‹¨ ì¤‘ ì˜¤ë¥˜: {str(e)}", "search_query": ""}


# ============================================================
# ëŒ€í‘œ ì§ˆë¬¸ìš© ë¯¸ë¦¬ ì •ì˜ëœ ë‹µë³€
# ============================================================
PREDEFINED_ANSWERS = {
    "ğŸ¯ ì§ë¬´ ì—­ëŸ‰ ë¶„ì„ë²•": """
ì´ ê³µê³ ì˜ í•µì‹¬ ì—­ëŸ‰ì€?

**ğŸ’¡ ì´ë ‡ê²Œ ì§ˆë¬¸í•´ ë³´ì„¸ìš”!**
> ğŸ’¬ "ì´ ê³µê³ ì˜ í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒ 3ê°€ì§€ì™€ ê·¸ ì´ìœ ë¥¼ ì•Œë ¤ì¤˜."

* **ì§ë¬´ ìŠ¤ìº”**: ê³µê³  ë‚´ í•µì‹¬ ì—­ëŸ‰ ì •ë°€ ì¶”ì¶œ
* **ìš°ì„ ìˆœìœ„**: í•„ìˆ˜ ìš”ê±´ê³¼ ìš°ëŒ€ ì‚¬í•­ ì™„ë²½ êµ¬ë¶„
* **ì§€ì› ì „ëµ**: ë³¸ì¸ì˜ ê²½í—˜ ì¤‘ ê°•ì¡°í•  í¬ì¸íŠ¸ ì œì•ˆ

**â¡ï¸ PDF ì—…ë¡œë“œ(ì¸ë±ì‹±) í›„ ì§ˆë¬¸í•˜ë©´ ë” ì •í™•í•©ë‹ˆë‹¤.**
    """,
    "ğŸ’¡ ë©´ì ‘ ëŒ€ë¹„ ë°©ë²•": """
ì‹¤ì „ ë©´ì ‘ ì¤€ë¹„ê°€ í•„ìš”í•˜ì‹ ê°€ìš”?

**ğŸ’¡ ì´ë ‡ê²Œ ì§ˆë¬¸í•´ ë³´ì„¸ìš”!**
> ğŸ’¬ "ì´ ê³µê³  ê¸°ë°˜ ì˜ˆìƒ ì§ˆë¬¸ 5ê°œì™€ í•©ê²© ë‹µë³€ í‚¤ì›Œë“œ ì•Œë ¤ì¤˜."

* **ë§ì¶¤ ì§ˆë¬¸**: JD ê¸°ë°˜ ì‹¤ë¬´/ì¸ì„± ë©´ì ‘ ë¬¸í•­ ìƒì„±
* **ë‹µë³€ ê°€ì´ë“œ**: ë…¼ë¦¬ì ì¸ ë‹µë³€ì„ ìœ„í•œ í•µì‹¬ ê°€ì´ë“œ ì œê³µ
* **ì‹¤ì „ ì—°ìŠµ**: "ë‚˜ë‘ ë©´ì ‘ ì—°ìŠµí•˜ì"ë¼ê³  ë§í•´ë³´ì„¸ìš”!

**â¡ï¸ ê³µê³  ë¶„ì„ í›„ ìš”ì²­í•˜ì‹œë©´ ê°€ì¥ ë‚ ì¹´ë¡œìš´ ì§ˆë¬¸ì´ ë‚˜ì˜µë‹ˆë‹¤.**
    """,
    "ğŸ“Š ì—°ë´‰/íŠ¸ë Œë“œ í™•ì¸ë²•": """
ì—…ê³„ íŠ¸ë Œë“œì™€ ì—°ë´‰ì´ ê¶ê¸ˆí•˜ë‹¤ë©´?

**ğŸ’¡ ì´ë ‡ê²Œ ì§ˆë¬¸í•´ ë³´ì„¸ìš”!**
> ğŸ’¬ "ì´ ì—…ê³„ ì‹ ì… ì—°ë´‰ ìˆ˜ì¤€ê³¼ ìµœì‹  ì±„ìš© íŠ¸ë Œë“œ ì•Œë ¤ì¤˜."

* **ì—°ë´‰ ë°ì´í„°**: ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ì²˜ìš° íŒŒì•…
* **ê¸°ìˆ  ë™í–¥**: í˜„ì¬ ì—…ê³„ì—ì„œ í•«í•œ ê¸°ìˆ ê³¼ ìê²©ì¦ ë¶„ì„
* **ê¸°ì—… ë¶„ì„**: ë©´ì ‘ í›„ê¸°ì™€ ê¸°ì—… ë¶„ìœ„ê¸° ì¢…í•© ìš”ì•½

**â¡ï¸ ì‹¤ì‹œê°„ ê²€ìƒ‰ì„ í†µí•´ ê°€ì¥ ìµœì‹  ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.**
    """,
}
   

# ============================================================
# ì‚¬ì´ë“œë°”
# ============================================================
with st.sidebar:
    logo_b64 = get_base64_image("kirby-puffy.png")
    if logo_b64:
        st.markdown(
            f'<img src="data:image/png;base64,{logo_b64}" width="100%">',
            unsafe_allow_html=True,
        )
    else:
        st.title("ğŸ¤– ìƒˆì‹¹ ìŠ¤ë§ˆíŠ¸ AI ì·¨ì—… ì»¨ì„¤í„´íŠ¸")

    st.divider()
    
    # ì§€ì‹ ë°ì´í„°ë² ì´ìŠ¤ ì„¹ì…˜
    st.subheader("ğŸ“š ì§€ì‹ ë°ì´í„°ë² ì´ìŠ¤")
    if st.button("ë¬¸ì„œ ì¸ë±ì‹± ì‹œì‘"):
        perform_indexing()
    if st.session_state.vector_store:
        st.caption("âœ… ë¬¸ì„œ í•™ìŠµ ì™„ë£Œ")

    st.divider()
    
    # ì›¹ ê²€ìƒ‰ ì„¤ì • ì„¹ì…˜
    st.subheader("ğŸ” ì›¹ ê²€ìƒ‰ ì„¤ì •")
    search_sources = st.multiselect(
        "ê²€ìƒ‰ ì†ŒìŠ¤",
        ["ë„¤ì´ë²„ ë¸”ë¡œê·¸", "ë„¤ì´ë²„ ì¹´í˜"],
        default=["ë„¤ì´ë²„ ë¸”ë¡œê·¸", "ë„¤ì´ë²„ ì¹´í˜"],
    )
    num_results = st.slider("ì†ŒìŠ¤ë³„ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 3, 15, 5)
    
    st.divider()
    
# AI í˜ë¥´ì†Œë‚˜ ì„¤ì •
    st.subheader("AI í˜ë¥´ì†Œë‚˜ ì„¤ì •")
    system_instruction = st.text_area(
        "AI ì—­í•  ì •ì˜:",
        value="""ë„ˆëŠ” IT ì±„ìš© ì „ë¬¸ í—¤ë“œí—Œí„°ì´ì ì»¤ë¦¬ì–´ ì»¨ì„¤í„´íŠ¸ì•¼. 
ì‚¬ìš©ìê°€ ì±„ìš© ì •ë³´ë¥¼ ë¬¼ì–´ë³´ë©´ [Context]ë‚˜ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ 
[ì§ë¬´ ê°œìš”], [ìê²© ìš”ê±´], [ìš°ëŒ€ ì‚¬í•­]ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ì„œ ì•Œë ¤ì£¼ê³ , 
í•´ë‹¹ ì§ë¬´ì— í•©ê²©í•˜ê¸° ìœ„í•œ ì»¤ë¦¬ì–´ ì¡°ì–¸ë„ í•œ ì¤„ ë§ë¶™ì—¬ì¤˜.""",
        height=150,
    )

    
    st.divider()
    
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.search_history = []
        st.rerun()
    
    # í†µê³„ í‘œì‹œ
    st.divider()
    st.subheader("ğŸ“Š ì‚¬ìš© í†µê³„")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("ëŒ€í™” ìˆ˜", len(st.session_state.messages) // 2)
    with col2:
        st.metric("ì›¹ ê²€ìƒ‰", len(st.session_state.search_history))

# ============================================================
# ë©”ì¸ í™”ë©´
# ============================================================
st.markdown(
    "<h2 style='color: #0066cc;'>ìƒˆì‹¹ ìŠ¤ë§ˆíŠ¸ AI ì·¨ì—… ì»¨ì„¤í„´íŠ¸</h2>", unsafe_allow_html=True
)
st.caption("ğŸš€ AI ì·¨ì—… ì»¨ì„¤í„´íŠ¸ | PDF ê³µê³  ë¶„ì„ë¶€í„° ìµœì‹  ì±„ìš© íŠ¸ë Œë“œ ê²€ìƒ‰ê¹Œì§€, ë‹¹ì‹ ë§Œì˜ í•©ê²© ì „ëµì„ ì„¤ê³„í•©ë‹ˆë‹¤.")

st.markdown("### ğŸ’¡ ë¬´ì—‡ì„ ë¬¼ì–´ë´ì•¼ í• ì§€ ëª¨ë¥´ê² ë‹¤ë©´? í´ë¦­í•´ì„œ ê°€ì´ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”!")
col1, col2, col3 = st.columns(3)
q1 = "ğŸ¯ ì§ë¬´ ì—­ëŸ‰ ë¶„ì„ë²•"
q2 = "ğŸ’¡ ë©´ì ‘ ëŒ€ë¹„ ë°©ë²•"
q3 = "ğŸ“Š ì—°ë´‰/íŠ¸ë Œë“œ í™•ì¸ë²•"

clicked_q = None
if col1.button("ğŸ¯ ì§ë¬´ ì—­ëŸ‰ ë¶„ì„ë²•"):
    clicked_q = q1
if col2.button("ğŸ’¡ ë©´ì ‘ ëŒ€ë¹„ ë°©ë²•"):
    clicked_q = q2
if col3.button("ğŸ“Š ì—°ë´‰/íŠ¸ë Œë“œ í™•ì¸ë²•"):
    clicked_q = q3

st.divider()

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for msg in st.session_state.messages:
    if isinstance(msg, HumanMessage):
        st.markdown(
            f'<div class="user-box">{msg.content}</div>', unsafe_allow_html=True
        )
    elif isinstance(msg, AIMessage):
        st.markdown(f'<div class="ai-box">{msg.content}</div>', unsafe_allow_html=True)

user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: ì±„ìš©ê³µê³  ë¶„ì„, ë©´ì ‘ ëŒ€ë¹„ë²• ë“±)")
final_query = clicked_q if clicked_q else user_input

if final_query:
    st.markdown(f'<div class="user-box">{final_query}</div>', unsafe_allow_html=True)
    st.session_state.messages.append(HumanMessage(content=final_query))

    # ë‹µë³€ ìƒì„± ë¡œì§
    if final_query in PREDEFINED_ANSWERS:
        # ë¯¸ë¦¬ ì •ì˜ëœ ë‹µë³€
        ai_content = PREDEFINED_ANSWERS[final_query]
        mode_badge = '<span class="mode-badge mode-rag">ğŸ“š ì‚¬ì „ ì •ì˜ ë‹µë³€</span>'
    else:
        # ì§ˆë¬¸ ë¶„ë¥˜
        query_type = classify_query(final_query, st.session_state.vector_store is not None)
        
        try:
            if query_type == "RAG":
                # RAG ëª¨ë“œ (SeSAC/êµìœ¡ ê´€ë ¨)
                mode_badge = '<span class="mode-badge mode-rag">ğŸ“š RAG ëª¨ë“œ (êµìœ¡ ì •ë³´)</span>'
                
                context = ""
                if st.session_state.vector_store:
                    docs = st.session_state.vector_store.similarity_search(final_query, k=3)
                    context = "\n\n".join([doc.page_content for doc in docs])

                llm = ChatOpenAI(
                    model="gpt-5-mini",
                    api_key=st.secrets["OPENAI_API_KEY"],
                    streaming=True,
                    temperature=1,
                )

                full_system_prompt = f"{system_instruction}\n\n[Context]\n{context if context else 'ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ'}"
                prompt = [
                    SystemMessage(content=full_system_prompt)
                ] + st.session_state.messages

                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    response = llm.invoke(prompt)
                    ai_content = response.content
                    
            else:
                # AUTO ëª¨ë“œ: LLMì´ ì›¹ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ íŒë‹¨
                with st.spinner("ì§ˆë¬¸ ë¶„ì„ ì¤‘..."):
                    search_decision = determine_search_need(final_query, st.secrets["OPENAI_API_KEY"])
                
                if search_decision["need_search"]:
                    # ì›¹ ê²€ìƒ‰ ëª¨ë“œ
                    mode_badge = '<span class="mode-badge mode-web">ğŸ” ì›¹ ê²€ìƒ‰ ëª¨ë“œ</span>'
                    
                    search_query = search_decision["search_query"] if search_decision["search_query"] else final_query
                    
                    with st.status(f"ğŸ” ì›¹ì—ì„œ '{search_query}' ê²€ìƒ‰ ì¤‘...", expanded=True) as status:
                        all_results = []
                        seen_links = set()
                        
                        # ê²€ìƒ‰ ì‹¤í–‰
                        results = search_web(search_query, search_sources, num_results)
                        
                        for result in results:
                            if result["link"] not in seen_links:
                                seen_links.add(result["link"])
                                all_results.append(result)
                        
                        st.write(f"âœ… {len(all_results)}ê°œì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                        st.caption(f"ğŸ’¡ íŒë‹¨ ì´ìœ : {search_decision['reason']}")
                        status.update(label="ê²€ìƒ‰ ì™„ë£Œ!", state="complete")
                    
                    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                    if all_results:
                        with st.expander("ğŸ“‘ ê²€ìƒ‰ëœ ì›ë³¸ ìë£Œ ë³´ê¸°", expanded=False):
                            for i, result in enumerate(all_results[:10], 1):
                                st.markdown(
                                    f"""
                                <div class="search-result">
                                    <strong>{i}. {result['title']}</strong><br>
                                    <span class="source-link">ğŸ”— <a href="{result['link']}" target="_blank">{result['source']}</a></span><br>
                                    <small>{result['snippet'][:200]}...</small>
                                </div>
                                """,
                                    unsafe_allow_html=True,
                                )
                        
                        # ê²€ìƒ‰ ê¸°ë¡ ì €ì¥
                        st.session_state.search_history.append({
                            "query": search_query,
                            "results_count": len(all_results),
                        })
                    
                    # ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
                    web_context = ""
                    for i, result in enumerate(all_results, 1):
                        web_context += f"\n[ê²°ê³¼ {i}]\n"
                        web_context += f"ì œëª©: {result['title']}\n"
                        web_context += f"ì¶œì²˜: {result['source']}\n"
                        web_context += f"ë§í¬: {result['link']}\n"
                        web_context += f"ë‚´ìš©: {result['snippet']}\n"
                    
                    # LLMìœ¼ë¡œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„
                    llm = ChatOpenAI(
                        model="gpt-5-mini",
                        api_key=st.secrets["OPENAI_API_KEY"],
                        streaming=True,
                        temperature=1,
                    )
                    
                    web_system_prompt = f"""{system_instruction}

ì•„ë˜ëŠ” ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì›¹ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ ì‹œ ì¶œì²˜ ë§í¬ë¥¼ í•¨ê»˜ í‘œì‹œí•´ì£¼ì„¸ìš”.

[ì›¹ ê²€ìƒ‰ ê²°ê³¼]
{web_context if web_context else 'ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ'}"""

                    prompt = [
                        SystemMessage(content=web_system_prompt)
                    ] + st.session_state.messages
                    
                    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                        response = llm.invoke(prompt)
                        ai_content = response.content
                else:
                    # ì¼ë°˜ LLM ëª¨ë“œ (ì›¹ ê²€ìƒ‰ ë¶ˆí•„ìš”)
                    mode_badge = '<span class="mode-badge" style="background-color:#fff3e0;color:#e65100;">ğŸ§  AI ì§ì ‘ ë‹µë³€</span>'
                    
                    llm = ChatOpenAI(
                        model="gpt-5-mini",
                        api_key=st.secrets["OPENAI_API_KEY"],
                        streaming=True,
                        temperature=1,
                    )
                    
                    # ì¼ë°˜ ë‹µë³€ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì›¹ ê²€ìƒ‰ ì–¸ê¸‰ ì œê±°)
                    general_system_prompt = "ë„ˆëŠ” ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì¤˜."

                    prompt = [
                        SystemMessage(content=general_system_prompt)
                    ] + st.session_state.messages

                    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                        response = llm.invoke(prompt)
                        ai_content = response.content
                    
        except Exception as e:
            ai_content = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
            mode_badge = '<span class="mode-badge" style="background-color:#ffebee;color:#c62828;">âš ï¸ ì˜¤ë¥˜</span>'

    # ë‹µë³€ í‘œì‹œ
    st.markdown(mode_badge, unsafe_allow_html=True)
    st.markdown(f'<div class="ai-box">{ai_content}</div>', unsafe_allow_html=True)
    st.session_state.messages.append(AIMessage(content=ai_content))

# í•˜ë‹¨ ì•ˆë‚´
st.divider()
st.caption(
    """
ğŸ’¡ **ì‚¬ìš© ì•ˆë‚´**: 

âœ… **SeSAC êµìœ¡ ì •ë³´ (RAG ëª¨ë“œ)**
- êµìœ¡ê³¼ì • ì•ˆë‚´, ìˆ˜ê°• í›„ê¸°, ì„±ë™ìº í¼ìŠ¤ ì´ìš© ê°€ì´ë“œ ë“±
- ì‚¬ì´ë“œë°”ì—ì„œ **[ë¬¸ì„œ ì¸ë±ì‹±]** ì™„ë£Œ ì‹œ ì²¨ë¶€ëœ ê°€ì´ë“œë¶ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.

âœ… **ê¸°ì—… ê³µê³  ë° ì·¨ì—… ì •ë³´ (ì›¹ ê²€ìƒ‰ ëª¨ë“œ)**
- íŠ¹ì • ê¸°ì—…(í† ìŠ¤, í˜„ëŒ€ì°¨ ë“±)ì˜ ì‹¤ì‹œê°„ ì±„ìš© ê³µê³  ë° ì§ë¬´ ë¶„ì„
- ìµœì‹  ì—°ë´‰ ì •ë³´, ë©´ì ‘ í›„ê¸°, ì—…ê³„ íŠ¸ë Œë“œ ë‰´ìŠ¤ ë“±
- AIê°€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ **ğŸ” ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰**ì„ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

âœ… **ì¼ë°˜ ì§€ì‹ ë° ì»¨ì„¤íŒ… (AI ì§ì ‘ ë‹µë³€)**
- ìì†Œì„œ ì²¨ì‚­ ê°€ì´ë“œ, ë©´ì ‘ ë‹µë³€ êµ¬ì¡°í™”(STAR ê¸°ë²•), ì¼ë°˜ì ì¸ IT ê°œë… ì„¤ëª… ë“±
- AIì˜ í•™ìŠµëœ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì¦‰ì‹œ ìµœì ì˜ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
"""
)